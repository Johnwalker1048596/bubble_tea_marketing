import pandas as pd
from sqlalchemy import create_engine, text
import re
import os

# ==========================================
# 1. ç’°å¢ƒåˆå§‹åŒ–èˆ‡é»ƒé‡‘è¦å‰‡
# ==========================================
DB_URL = "postgresql://postgres:postgres@localhost:5432/bubble_tea"
engine = create_engine(DB_URL)

BRAND_MAP = {
    "åŠŸå¤«èŒ¶": "åŠŸå¤«èŒ¶", "å¤§èŒ—": "å¤§èŒ—æœ¬ä½åˆ¶èŒ¶å ‚", "å¾—æ­£": "å¾—æ­£", "å…ˆå–é“": "å…ˆå–é“",
    "æ¸…å¿ƒç¦å…¨": "æ¸…æ–°ç¦å…¨", "æ¸…æ–°ç¦å…¨": "æ¸…æ–°ç¦å…¨", "è¿·å®¢å¤": "è¿·å…‹å¤", "è¿·å…‹å¤": "è¿·å…‹å¤",
    "comebuy": "Comebuy", "é¾œè¨˜": "é¾œè¨˜", "50åµ": "äº”ååµ", "cocoéƒ½å¯": "Cocoéƒ½å¯"
}

# ğŸ§¬ åˆæ³•é£²æ–™çµå°¾ (å¢åŠ äº† 'æ°´'ï¼Œå› ç‚ºå…ˆå–é“æœ‰ 'ç«ç‘°æ°´')
VALID_SUFFIXES = ('èŒ¶', 'å¥¶', 'æ‹¿éµ', 'é’', 'ç¶ ', 'ç´…', 'çƒé¾', 'å†°æ²™', 'é®®å¥¶', 'å¥¶è“‹', 'ç‘ªå¥‡æœµ', 'æ­è•¾', 'é£²', 'éœ²', 'æ±', 'é¦™', 'å¯¶', 'å¤šå¤š', 'ç‰›å¥¶', 'è•éº¥', 'å’–å•¡', 'ç¾å¼', 'ç¿¡ç¿ ', 'ç¿ ', 'ç‚®', 'å†¬ç“œ', 'ä»™è‰', 'æ„›ç‰', 'è±†æ¼¿', 'ç‡•éº¥', 'Q', 'æœ', 'å†°', 'å‡', 'æª¸', 'æŸš', 'è“', 'æ¢…', 'è˜‹', 'æ¡”', 'æ™®æ´±', 'æ°´')

# ğŸš« æ³›ç”¨èªèˆ‡å»¢è©± (çµ•å°ä¸èƒ½æŠ“)
BLACK_LIST = ['è²·ä¸€é€ä¸€', 'å„ªæƒ ', 'æ¨è–¦', 'æ–°å“', 'é™å®š', 'æ‰‹æ–', 'é£²æ–™', 'æ–°ä¸Šå¸‚', 'å›æ­¸', 'ç¾é£Ÿ', 'å°åŒ—', 'å°ä¸­', 'é«˜é›„', 'é–€å¸‚', 'æ´»å‹•', 'åŠ ç¢¼', 'æ—¥å¸¸', 'å£æ„Ÿ', 'æ»‹å‘³', 'å¥½å–', 'é™æ™‚', 'é–‹è³£', 'ç‰¹èª¿', 'é¦™é†‡', 'ç ”ç£¨', 'åš´é¸', 'é¢¨å‘³', 'ç¨å®¶', 'ç”œèœœ', 'æŸ”è»Ÿ', 'å…¨å°', 'ä¸Šå¸‚', 'è¯å', 'å°ˆå±¬', 'æ¸…çˆ½', 'ç²¾æ²¹', 'å¤©èŠ±æ¿', 'éš±è—ç‰ˆ', 'è¶…å€¼çµ„åˆ', 'é›»å½±', 'ä½œå“', 'å¥½å‹æ—¥', 'å¥½èŒ¶', 'å°ˆè³£åº—', 'æ­é…', 'é–‹å±€', 'å€’æ•¸', 'å°ç·¨', 'å¥½å¿ƒæƒ…', 'å¤§æ¯', 'ä¸­æ¯', 'å…è²»', 'åŠåƒ¹', 'æŠ˜æ‰£', 'æŠ˜åƒ¹', 'é£²å“', 'å¥½ç‰©', 'å“ç‰Œ', 'æ™‚å…‰', 'ç³»åˆ—', 'ç”œå®¤', 'ç¥éšŠå‹', 'å¤§æ¨', 'é¦–é¸', 'å¿…é»', 'æœé†¬', 'æ‰‹å·¥', 'é…æ–™', 'åŠ æ–™', 'ç²‰', 'ç³–æ¼¿', 'ç„¡ç³–èŒ¶', 'å°ç£èŒ¶', 'ä¸‹åˆèŒ¶', 'ç´”èŒ¶', 'ç²¾å“èŒ¶', 'æœ¬ä½è£½èŒ¶', 'ä¸–ç•Œä¸‰å¤§ç´…èŒ¶', 'æ–°å¹´å–å¥½èŒ¶', 'è‹±åœ‹èŒ¶', 'å°ç£å››å¤§åèŒ¶', 'ç†±é£²', 'å†·é£²', 'å†°é£²', 'ç¶ èŒ¶å°ˆè³£åº—', 'ç¶“å…¸å›æ­¸', 'é›™é¥—èŒ¶æœƒ', 'ä»¥èŒ¶ç›¸èš', 'å–®å“ç´…', 'åŸèŒ¶', 'èƒ½é‡é£²', 'ç‰¹èª¿èŒ¶', 'ç±³å…¶æ—', 'å¤å…¸ç«ç‘°åœ’']

# ==========================================
# 2. æ·±åº¦æ¢å‹˜é‚è¼¯
# ==========================================
def load_menu_dict(file_path):
    menu = {}
    if not os.path.exists(file_path): return menu
    try:
        df = pd.read_excel(file_path).fillna('')
        for _, row in df.iterrows():
            brand = str(row.get('brand', '')).strip()
            item = str(row.get('item_name', '')).strip()
            if not brand or not item: continue
            db_brand = BRAND_MAP.get(brand, brand)
            if db_brand not in menu: menu[db_brand] = []
            menu[db_brand].append(item)
    except: pass
    return menu

def clean_text_for_mining(text_content):
    """æ¸…é™¤ç ´åœ– Emoji (å¦‚ ) èˆ‡ç„¡ç”¨æ¨™é»"""
    # åªä¿ç•™ä¸­è‹±æ–‡ã€æ•¸å­—ã€å¸¸è¦‹ä¸­æ–‡æ¨™é»èˆ‡æ›è¡Œ
    clean = re.sub(r'[^\w\s\u4e00-\u9fa5ï¼Œã€‚ï¼ï¼Ÿã€ï¼›ï¼šã€Œã€ã€ã€ã€Šã€‹()ï¼ˆï¼‰#\n]', '', text_content)
    return clean

def deep_mine_final_text(raw_text, store_name, menu_dict):
    """å¾æ–‡æ¡ˆå…¨æ–‡ä¸­é€²è¡Œæ·±åº¦æ¢å‹˜"""
    found_drinks = set()
    cleaned_text = clean_text_for_mining(raw_text)
    
    # ã€æˆ°è¡“ä¸€ï¼šèœå–®é»ƒé‡‘æ¯”å°ã€‘ (æœ€ç©©)
    # åªè¦æ–‡æ¡ˆè£¡å‡ºç¾èœå–®ä¸Šçš„åå­—ï¼Œç›´æ¥æŠ“ï¼ä¸ç®¡æœ‰æ²’æœ‰æ¨™ç±¤ã€‚
    if store_name in menu_dict:
        # å¾é•·åº¦é•·çš„é–‹å§‹æ¯”å°ï¼Œé¿å…ã€Œçƒé¾ç¶ èŒ¶ã€è¢«åˆ‡æˆã€Œç¶ èŒ¶ã€
        for valid_prod in sorted(menu_dict[store_name], key=len, reverse=True):
            if valid_prod in cleaned_text:
                found_drinks.add(valid_prod)
                
    # ã€æˆ°è¡“äºŒï¼šæ–·å¥ç‰¹å¾µæƒæã€‘ (å°ˆæŠ“è£¸å¥”æ–°å“ï¼Œå¦‚ï¼šå†¬éŸ»æ“‚ç„™çå¥¶)
    # å¦‚æœæˆ°è¡“ä¸€æ²’æŠ“åˆ°æ±è¥¿ï¼ˆä»£è¡¨å¯èƒ½æ˜¯æ–°å“ï¼‰
    if not found_drinks:
        # ç”¨æ¨™é»ç¬¦è™Ÿã€æ›è¡Œã€ç©ºæ ¼æŠŠæ–‡ç« åˆ‡æˆä¸€å¡Šä¸€å¡Šçš„è©
        chunks = re.split(r'[\s\nï¼Œã€‚ï¼ï¼Ÿã€ï¼›ï¼šã€Œã€ã€ã€ã€Šã€‹()ï¼ˆï¼‰#]+', cleaned_text)
        for chunk in chunks:
            c = chunk.strip()
            # å¿…é ˆé•·åº¦åœ¨ 2~8 å­—ï¼Œä¸¦ä¸”ä»¥é£²æ–™å­—çœ¼çµå°¾
            if 2 <= len(c) <= 8 and any(c.endswith(s) for s in VALID_SUFFIXES):
                # æ’é™¤æ³›ç”¨èªèˆ‡å»¢è©±é»‘åå–®
                if not any(b in c for b in BLACK_LIST):
                    found_drinks.add(c)
                    
    return list(found_drinks)

# ==========================================
# 3. åŸ·è¡Œè³‡æ–™åº«ä¿®å¾©
# ==========================================
def run_deep_miner():
    print("â›ï¸ å•Ÿå‹• ELT ç¬¬ä¸‰å±¤ï¼šfinal_text å…¨æ–‡æ·±åº¦æ¢å‹˜...")
    menu_dict = load_menu_dict("beverage_with_fruit_column.xlsx")
    
    with engine.connect() as conn:
        # æŠŠç›®å‰ç©ºå€¼æˆ–æ€ªæ€ªçš„è³‡æ–™æ’ˆå‡ºä¾†é‡æ–°æƒæ
        df = pd.read_sql(text("""
            SELECT m.id, m.final_text, s.name as store_name, m.store_id, m.platform, m.created_at, m."Like"
            FROM marketing_content m
            JOIN store s ON m.store_id = s.id
            WHERE m.product_name LIKE '%éœ€äººå·¥ç¢ºèª%' OR m.product_name LIKE '%OCR%'
        """), conn)
        
        updates = []
        new_inserts = []

        for _, row in df.iterrows():
            pid = row['id']
            raw_text = row['final_text']
            store_name = row['store_name']
            
            mined_drinks = deep_mine_final_text(raw_text, store_name, menu_dict)
            
            if mined_drinks:
                # æ•‘å›ç¬¬ä¸€æ¯ï¼ŒUPDATE è¦†è“‹æ‰åŸæœ¬çš„ç©ºå€¼
                updates.append({"id": pid, "product_name": f"[Deep-Mined] {mined_drinks[0]}"})
                
                # å¦‚æœåŒä¸€ç¯‡æ–‡æ¡ˆæŒ–å‡ºå¤šæ¯ (ä¾‹å¦‚ç«ç‘°æ°´ã€è‹±å¼ç«ç‘°æ‹¿éµ)ï¼Œå°± INSERT ä¿æŒå¹³å¦åŒ–
                if len(mined_drinks) > 1:
                    for extra in mined_drinks[1:]:
                        new_inserts.append({
                            "store_id": int(row['store_id']),
                            "platform": row['platform'],
                            "product_name": f"[Deep-Mined] {extra}",
                            "final_text": raw_text,
                            "created_at": row['created_at'],
                            "Like": int(row['Like'])
                        })

        if updates or new_inserts:
            with engine.begin() as tx:
                for u in updates:
                    tx.execute(text("UPDATE marketing_content SET product_name = :pname WHERE id = :id"), 
                               {"pname": u['product_name'], "id": u['id']})
                    print(f"âœ¨ æ·±åº¦æ¢å‹˜æˆåŠŸï¼æ›´æ–° ID {u['id']} -> {u['product_name']}")
                
                for ins in new_inserts:
                    tx.execute(text("""
                        INSERT INTO marketing_content (store_id, platform, product_name, final_text, created_at, "Like")
                        VALUES (:store_id, :platform, :product_name, :final_text, :created_at, :Like)
                    """), ins)
                    print(f"ğŸ›Ÿ æ·±åº¦æ¢å‹˜å¯«å…¥æ–°åˆ— -> {ins['product_name']}")
                    
            print(f"\nğŸ‰ æ¢å‹˜å®Œæˆï¼å…±ä¿®å¾©äº† {len(updates)} ç­†è³‡æ–™ï¼Œé¡å¤–æå–äº† {len(new_inserts)} æ¯éš±è—é£²å“ï¼")
        else:
            print("\nâœ… æ¢å‹˜å®Œç•¢ï¼Œæ²’æœ‰ç™¼ç¾å¯æ•‘å›çš„è³‡æ–™ã€‚")

if __name__ == "__main__":
    run_deep_miner()