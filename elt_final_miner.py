import pandas as pd
from sqlalchemy import create_engine, text
import re
import os

# ==========================================
# 1. ç’°å¢ƒåˆå§‹åŒ–èˆ‡é»ƒé‡‘è¦å‰‡
# ==========================================
DB_URL = "postgresql://postgres:postgres@localhost:5432/bubble_tea"
engine = create_engine(DB_URL)

BRAND_MAP = {
    "åŠŸå¤«èŒ¶": "åŠŸå¤«èŒ¶", "å¤§èŒ—": "å¤§èŒ—æœ¬ä½åˆ¶èŒ¶å ‚", "å¾—æ­£": "å¾—æ­£", "å…ˆå–é“": "å…ˆå–é“",
    "æ¸…å¿ƒç¦å…¨": "æ¸…æ–°ç¦å…¨", "æ¸…æ–°ç¦å…¨": "æ¸…æ–°ç¦å…¨", "è¿·å®¢å¤": "è¿·å…‹å¤", "è¿·å…‹å¤": "è¿·å…‹å¤",
    "comebuy": "Comebuy", "é¾œè¨˜": "é¾œè¨˜", "50åµ": "äº”ååµ", "cocoéƒ½å¯": "Cocoéƒ½å¯"
}

BRAND_EXCLUDE = ["åŠŸå¤«èŒ¶", "KUNGFUTEA", "å¤§èŒ—æœ¬ä½åˆ¶èŒ¶å ‚", "å¤§èŒ—æœ¬ä½è£½èŒ¶å ‚", "æœ¬ä½è£½èŒ¶å ‚", "æœ¬ä½åˆ¶èŒ¶å ‚", "å¤§èŒ—", "æœ¬ä½è£½èŒ¶", "DAMING", "å¾—æ­£", "å…ˆå–é“", "æ¸…æ–°ç¦å…¨", "æ¸…å¿ƒç¦å…¨", "è¿·å®¢å¤", "è¿·å…‹å¤", "MILKSHA", "COMEBUY", "é¾œè¨˜", "GUIJI", "äº”ååµ", "50åµ", "COCO", "éƒ½å¯"]

VALID_SUFFIXES = ('èŒ¶', 'å¥¶', 'æ‹¿éµ', 'é’', 'ç¶ ', 'ç´…', 'çƒé¾', 'å†°æ²™', 'é®®å¥¶', 'å¥¶è“‹', 'ç‘ªå¥‡æœµ', 'æ­è•¾', 'é£²', 'éœ²', 'æ±', 'é¦™', 'å¯¶', 'å¤šå¤š', 'ç‰›å¥¶', 'è•éº¥', 'å’–å•¡', 'ç¾å¼', 'ç¿¡ç¿ ', 'ç¿ ', 'ç‚®', 'å†¬ç“œ', 'ä»™è‰', 'æ„›ç‰', 'è±†æ¼¿', 'ç‡•éº¥', 'Q', 'æœ', 'å†°', 'å‡', 'æª¸', 'æŸš', 'è“', 'æ¢…', 'è˜‹', 'æ¡”', 'æ™®æ´±', 'æ°´')

BLACK_LIST = [
    'è²·ä¸€é€ä¸€', 'å„ªæƒ ', 'æ¨è–¦', 'æ–°å“', 'é™å®š', 'æ‰‹æ–', 'é£²æ–™', 'æ–°ä¸Šå¸‚', 'å›æ­¸', 'ç¾é£Ÿ', 'å°åŒ—', 'å°ä¸­', 'é«˜é›„', 'é–€å¸‚', 'æ´»å‹•', 'åŠ ç¢¼', 'æ—¥å¸¸', 'å£æ„Ÿ', 'æ»‹å‘³', 'å¥½å–', 'é™æ™‚', 'é–‹è³£', 'ç‰¹èª¿', 'é¦™é†‡', 'ç ”ç£¨', 'åš´é¸', 'é¢¨å‘³', 'ç¨å®¶', 'ç”œèœœ', 'æŸ”è»Ÿ', 'å…¨å°', 'ä¸Šå¸‚', 'è¯å', 'å°ˆå±¬', 'æ¸…çˆ½', 'ç²¾æ²¹', 'å¤©èŠ±æ¿', 'éš±è—ç‰ˆ', 'è¶…å€¼çµ„åˆ', 'é›»å½±', 'ä½œå“', 'å¥½å‹æ—¥', 'å¥½èŒ¶', 'å°ˆè³£åº—', 'æ­é…', 'é–‹å±€', 'å€’æ•¸', 'å°ç·¨', 'å¥½å¿ƒæƒ…', 'å¤§æ¯', 'ä¸­æ¯', 'å…è²»', 'åŠåƒ¹', 'æŠ˜æ‰£', 'æŠ˜åƒ¹', 'é£²å“', 'å¥½ç‰©', 'å“ç‰Œ', 'æ™‚å…‰', 'ç³»åˆ—', 'ç”œå®¤', 'ç¥éšŠå‹', 'å¤§æ¨', 'é¦–é¸', 'å¿…é»', 'æœé†¬', 'æ‰‹å·¥', 'é…æ–™', 'åŠ æ–™', 'ç²‰', 'ç³–æ¼¿', 'ç„¡ç³–èŒ¶', 'å°ç£èŒ¶', 'ä¸‹åˆèŒ¶', 'ç´”èŒ¶', 'ç²¾å“èŒ¶', 'æœ¬ä½è£½èŒ¶', 'ä¸–ç•Œä¸‰å¤§ç´…èŒ¶', 'æ–°å¹´å–å¥½èŒ¶', 'è‹±åœ‹èŒ¶', 'å°ç£å››å¤§åèŒ¶', 'ç†±é£²', 'å†·é£²', 'å†°é£²', 'ç¶ èŒ¶å°ˆè³£åº—', 'ç¶“å…¸å›æ­¸', 'é›™é¥—èŒ¶æœƒ', 'ä»¥èŒ¶ç›¸èš', 'å–®å“ç´…', 'åŸèŒ¶', 'èƒ½é‡é£²', 'ç‰¹èª¿èŒ¶', 'ç±³å…¶æ—', 'å¤å…¸ç«ç‘°åœ’',
    'æ¿ƒéƒ', 'å¥¶é¦™', 'å¾—ç', 'èŒ¶æ¹¯', 'æ¸…é¦™', 'æ²æ¶¼', 'é®®æœ', 'å–èŒ¶', 'å›å®¶', 'è·¯ä¸Š', 'ç„¡è«–', 'æ¯ä¸€', 'ä¸åª', 'ä¸€æ¯', 'æ¯å¤©', 'åªæ˜¯',
    'è‰è“', 'è”“è¶Šè“', 'è˜‹æœ', 'èŠ’æœ', 'è‘¡è„æŸš', 'æª¸æª¬', 'ç™¾é¦™æœ', 'é‡‘æ¡”'
]

PREFIX_STRIP = ['å…¨æ°‘å–', 'ç¾æ¨‚è’‚æœ€æ„›', 'æœ€æ„›', 'æŠŠ', 'ä¾†æ¯', 'å–æ¯', 'ä¸€æ¯', 'é€™æ¯', 'æ¨è–¦', 'è¶…æ„›', 'å¿…å–', 'å…¨æ–°', 'äººæ°£', 'å–', 'æ˜¯', 'é»', 'çš„']

# ==========================================
# 2. æ·±åº¦æ¢å‹˜é‚è¼¯
# ==========================================
def load_menu_dict(file_path):
    menu = {}
    if not os.path.exists(file_path): return menu
    try:
        df = pd.read_excel(file_path).fillna('')
        for _, row in df.iterrows():
            brand = str(row.get('brand', '')).strip()
            item = str(row.get('item_name', '')).strip()
            if not brand or not item: continue
            db_brand = BRAND_MAP.get(brand, brand)
            if db_brand not in menu: menu[db_brand] = []
            menu[db_brand].append(item)
    except: pass
    return menu

def clean_chunk(chunk):
    c = chunk.strip()
    for b in sorted(BRAND_EXCLUDE, key=len, reverse=True):
        c = c.replace(b, "")
    while True:
        changed = False
        for p in PREFIX_STRIP:
            if c.startswith(p):
                c = c[len(p):]
                changed = True
        if not changed: break
    return c.strip()

def deep_mine_final_text(raw_text, store_name, menu_dict):
    found_drinks = set()
    cleaned_text = re.sub(r'[^\w\s\u4e00-\u9fa5ï¼Œã€‚ï¼ï¼Ÿã€ï¼›ï¼šã€Œã€ã€ã€ã€Šã€‹()ï¼ˆï¼‰#\n]', '', raw_text)
    
    if store_name in menu_dict:
        for valid_prod in sorted(menu_dict[store_name], key=len, reverse=True):
            if valid_prod in BRAND_EXCLUDE or valid_prod == store_name:
                continue
            if valid_prod in cleaned_text:
                found_drinks.add(valid_prod)
                
    if not found_drinks:
        chunks = re.split(r'[\s\nï¼Œã€‚ï¼ï¼Ÿã€ï¼›ï¼šã€Œã€ã€ã€ã€Šã€‹()ï¼ˆï¼‰#]+', cleaned_text)
        for chunk in chunks:
            c = clean_chunk(chunk)
            if 2 <= len(c) <= 8 and any(c.endswith(s) for s in VALID_SUFFIXES):
                if not any(b in c for b in BLACK_LIST):
                    found_drinks.add(c)
                    
    return list(found_drinks)

# ==========================================
# 3. åŸ·è¡Œè³‡æ–™åº«å¤§æ¸…æ´—èˆ‡è·¨å¹³å°å»é‡
# ==========================================
def run_deep_miner():
    print("â›ï¸ å•Ÿå‹• ELT çµ‚æ¥µé˜²è­·ç¶²ï¼šè£ç”²æ¢å‹˜ + å®‰å…¨å»é‡...")
    menu_dict = load_menu_dict("beverage_with_fruit_column.xlsx")
    
    with engine.connect() as conn:
        # ğŸš¨ çµ•å°ä¸ç¢° OCRï¼Œåªæ•‘ç©ºå€¼è·Ÿé‡å¯© Deep-Mined
        df = pd.read_sql(text("""
            SELECT m.id, m.final_text, s.name as store_name, m.store_id, m.platform, m.created_at, m."Like"
            FROM marketing_content m
            JOIN store s ON m.store_id = s.id
            WHERE m.product_name LIKE '%éœ€äººå·¥ç¢ºèª%' 
               OR m.product_name LIKE '%Deep-Mined%'
        """), conn)
        
        updates = []
        new_inserts = []

        for _, row in df.iterrows():
            pid = row['id']
            raw_text = row['final_text']
            store_name = row['store_name']
            
            mined_drinks = deep_mine_final_text(raw_text, store_name, menu_dict)
            
            if mined_drinks:
                updates.append({"id": pid, "product_name": f"[Deep-Mined] {mined_drinks[0]}"})
                if len(mined_drinks) > 1:
                    for extra in mined_drinks[1:]:
                        new_inserts.append({
                            "store_id": int(row['store_id']),
                            "platform": row['platform'],
                            "product_name": f"[Deep-Mined] {extra}",
                            "final_text": raw_text,
                            "created_at": row['created_at'],
                            "Like": int(row['Like'])
                        })
            else:
                updates.append({"id": pid, "product_name": "[éœ€äººå·¥ç¢ºèª] åœ–ç‰‡é™å®šæˆ–ç„¡é£²å“"})

        with engine.begin() as tx:
            for u in updates:
                tx.execute(text("UPDATE marketing_content SET product_name = :pname WHERE id = :id"), 
                           {"pname": u['product_name'], "id": u['id']})
            for ins in new_inserts:
                tx.execute(text("""
                    INSERT INTO marketing_content (store_id, platform, product_name, final_text, created_at, "Like")
                    VALUES (:store_id, :platform, :product_name, :final_text, :created_at, :Like)
                """), ins)
            
            print(f"âœ¨ æ¢å‹˜å¯«å…¥å®Œæˆï¼æº–å‚™åŸ·è¡Œã€åŒå¹³å°é™å®šã€‘è³‡æ–™åº«å»é‡...")

            result = tx.execute(text("""
                DELETE FROM marketing_content a USING marketing_content b
                WHERE a.id > b.id 
                  AND a.platform = b.platform
                  AND a.store_id = b.store_id
                  AND a.final_text = b.final_text 
                  AND REGEXP_REPLACE(a.product_name, '^\\[.*?\\]\\s*', '') = REGEXP_REPLACE(b.product_name, '^\\[.*?\\]\\s*', '')
            """))
            print(f"ğŸ§¹ å¹³å°å®‰å…¨å»é‡å®Œæˆï¼æˆåŠŸæ¸…ç†äº† {result.rowcount} ç­†é‡è¤‡è³‡æ–™ã€‚")
            print(f"ğŸ‰ å…¨éƒ¨ä»»å‹™åŸ·è¡Œå®Œç•¢ï¼Œè³‡æ–™åº«å·²é”æœ€å®Œç¾ç‹€æ…‹ï¼")

if __name__ == "__main__":
    run_deep_miner()